List of references that have helped me in this implementation
- Attention is All you need paper : https://arxiv.org/abs/1706.03762
- TIM paper : https://openreview.net/forum?id=1TIrbngpW0x
- tf implementation of Transformer : https://www.tensorflow.org/tutorials/text/transformer
- https://pytorch.org/tutorials/beginner/transformer_tutorial.html
- https://pytorch.org/docs/master/_modules/torch/nn/modules/transformer.html#Transformer
- https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#MultiheadAttention
- https://github.com/pytorch/pytorch/blob/master/torch/nn/functional.py#L4511
- https://github.com/dhlee347/pytorchic-bert
- https://github.com/codertimo/BERT-pytorch
- https://github.com/Tikquuss/meta_XLM